# <font color ="red">ACQUISIZIONE DELLE IMMAGINI DIGITALI</font>
L'idea è che bisogna acquisire solo dei campioni di luce e non tutti insieme per rappresentare un'immagine dal mondo reale a 2D.
![[Pasted image 20221109145707.png|450]]
- Quando la luce colpisce un oggetto, una **parte** viene **assorbita** ed una **parte** viene **riflessa** e quest'ultima dà **origine al colore** percepito.
- Per creare una immagine digitale, è essenziale che tale luce riflessa sia catturata da un sensore ed elaborata.
C'è da considerare che solamente alcuni elementi dell'immagine avranno determinati valori nell'immagine digitale.

Il **sensore** è un "*qualcosa*" che è capace a rispondere a un determinato stimolo.
In particolare:
1. Maggiore è l'intensità dell'onda elettromagnetica che colpisce il sensore (esso si carica maggiormente) e maggiore è la corrente che rilascia.
2. *Più luce -> più carica del sensore -> più valori vicini al bianco.*

*Per esempio*:
1. Gli **scanner** usano un singolo sensore e, durante la scansione dell'immagine, il foglio non deve essere spostato.
   Più è lungo il tempo di scannerizzazione e più alto è il dettaglio ottenuto.
   *Quindi il tempo che impiega lo scanner (singolo sensore) non dà fastidio.*
   Invece, potrebbe dar fastidio se una fotocamera scattasse in 30 secondi, perchè l'immagine potrebbe cambiare.
2. La **TAC** usa dei sensori che sono disposti in un'unica linea. Esso può vedere tessuti interni tramite i *raggi X* ed essi vengono emessi dallo stesso oggetto (emettitore di raggi X) e i sensori rispondono esclusivamente ai *raggi X* per non creare confusione con altri tipi di luce.
3. Gli **scanner 3D** usano infrarossi. (*"kinnect" della Nintento Wii*) Proiettano una griglia nello spazio a infrarossi. Gli scanner riescono a ricostruire il volume di una scena grazie a questo reticolato.

## <font color ="blue">Sensori in 2D array</font>
- **Tutti gli elementi di una griglia (matrice**) **acquisiscono la luce** e "fanno qualcosa".
- I più diffusi sensori di questo tipo sono i **CCD** (*"Charged Coupled Device"*)
- Le celle del CCD **non possono caricarsi oltre un certo limite**: sono dei secchi di acqua che non possono riempirsi oltre alla loro capacità (fenomeno di ***sovra-saturazione***).
- Il **numero di celle** per area di esposizione è un parametro della qualità della fotocamera e si misura in **MEGAPIXEL**.
>16 Megapixel = array 2d di sensori con 16 milioni CCD

>- Dopo l'acquisizione dell'immagine avviene la **post produzione** e gli algoritmi sono abbastanza avanzati.
>- Dopo che i CCD acquisiscono energia, si caricano a seguito dei pacchetti di energia trasportati dalla luce (fotoni).
>- I CCD rilasciano corrente.
## <font color ="blue">Schema di misurazione</font>
L'acquisizione dell'immagine avviene nel seguente modo:
1. Viene letta la prima colonna a sinistra
2. Tutta l'energia della colonna (2) va nella colonna (1)
3. Viene letta nuovamente la prima colonna
4. ...In poche parole -- > **Sposto orizzontalmente e leggo una colonna verticalmente**
![[Pasted image 20221109151457.png|250]]

## <font color ="blue">La prima fotocamera digitale</font>
La prima fotocamera digitale avviene nel 1975 grazie a Steven Sasson. I dettagli di essa erano:
- Peso di 4 kg
- Risoluzione di 0,01 Megapixel
- Immagini di 100 x 100 pixel
- Memorizzazione su cassetta
- Tempo di memorizzazione di uno scatto su cassetta: 23 secondi.

*Il sensore descritto cattura o poca luce o tanta luce, quindi una scala di grigi.*

___Come si acquisiscono i 3 colori RGB?___
L'dea è quella di mettere su un pixel un filtro, per esempio rosso. Se ho luce rossa, allora il pixel si carica di rosso, altrimenti no. In un altro pixel metto un filtro verde e si ripete il procedimento.
Quindi il filtro serve per far passare solo un lunghezza d'onda (rosso, verde o blu)

>Un **CFA** è una matrice di filtri.

Visto che uno specifico sensore ha un solo filtro, gli altri 2 colori vengono interpolati.
Come vengono disposti i filtri? Ci sono vari **pattern**:
![[Pasted image 20221109160750.png|350]]
![[Pasted image 20221109160808.png|340]]
![[Pasted image 20221109160834.png|450]]
>Nelle celle bianche non ci sono filtri. Nelle zone nere non passa luce.

<div style="page-break-after: always; visibility: hidden"> \pagebreak </div>

## <font color ="blue">Bayer-Pattern</font>
Il più usato è il Bayern Pattern, ovvero:
![[Pasted image 20221109161100.png|300]]
- Esso ha il verde che compare in percentuale doppia rispetto agli altri due colori.
- Presenta un rapporto 1:2:1 per R:G:B, dove i pixel verdi sono disposti sulle “diagonali”.

>Esso privilegia le misure nel canale verde perché è quello più importante per la percezione umana.

Lo schema, generalmente, si indica indicando solo le prime 4 posizioni:
![[Pasted image 20221103112950.png|350]]

- Se si acquisisce solo con bayer pattern il formato dell'acquisizione è **RAW**. Finché non faccio l'interpolazione il risultato è solo un'unica matrice dove si alternano i 3 colori RGB.

- Sostanzialmente per RAW si intende **la non richiesta** di non eseguire l'interpolazione (3 matrici sovrapposte).

- In RAW ogni cella ha più di 8 bit, quindi 10-12-16.. e dopo l'interpolazione ogni cella occupa 8 bit

- Queste matrici di filtri vengono posti sopra il sensore

![[Pasted image 20221109161911.png|350]]

>L'immagine RAW è in scala di grigi (a livello pratico) e l'immagine a colori che si vede (dopo lo scatto) è risultato di un'interpolazione fatta "al volo" in fase di visualizzazione


# <font color ="red">COLOR INTERPOLATION</font>
Il «**demosaicking**» è l'algoritmo che viene richiamato in presenza di in presenza di CFA -> passo da bayer-pattern a immagini a colori mediante l'uso interpolazione.
![[Pasted image 20221103114307.png]]
Descrizione dell'immagine:
a) scala di grgi, raw, bayer pattern.
b) **Immagine a falsi colori** e si chiama così perchè per ogni cella posso avere solo un colore più o meno intenso. 
c) demosaiking applicata, quindi l'immagine è stata interpolata.

Ogni cella viene colpita dal riflesso di un oggetto che emette luce.
Il sensore acquisisce l'intensità luminosa e grazie al "filtro" fa passare in maniera "pura" un solo canale e gli altri vengono riflessi.
Per ottenere il colore finale devo avere, in ogni cella, la combinazione dei 3 canali. 
Pertanto interviene l'interpolazione.


## <font color ="blue">Nearest-neighbor interpolation (replication)</font>
![[Pasted image 20221103114751.png]]
Il rosso lo replico nelle direzioni delle frecce. Quindi interpolazione per replication.

## <font color ="blue">Bilineare</font>
### - Abbiamo l’informazione di Red(R) e manca Green(G) e Blue(B)
- Nella matrice di Red non si deve fare nulla.
- In Green occorre ricavare i dati da un intorno selezionando i 4 valori rilasciati dal sensore.
- In Blue occorre ricavare i dati da un intorno selezionando i 4 valori rilasciati dal sensore.
![[Pasted image 20221109165222.png|450]]

<div style="page-break-after: always; visibility: hidden"> \pagebreak </div>

### - Abbiamo l’informazione di G e manca R e B
- Nella matrice di G non si deve fare nulla.
- In R occorre ricavare i dati da un intorno selezionando i 2 valori rilasciati dal sensore.
- In B occorre ricavare i dati da un intorno selezionando i 2 valori rilasciati dal sensore
![[Pasted image 20221109165452.png|450]]
### - Abbiamo l’informazione di B e manca R e G
- Nella matrice di B non si deve fare nulla. 
- In R occorre ricavare i dati da un intorno selezionando i 4 valori rilasciati dal sensore. 
- In G occorre ricavare i dati da un intorno selezionando i 4 valori rilasciati dal sensore.
![[Pasted image 20221109165504.png|450]]


Con la replication si presentano le scalettature, come nell'esempio:
![[Pasted image 20221103115610.png|450]]

## <font color ="blue">Risoluzione</font>
Si dice **risoluzione** il numero di pixel per unità di misura, **cioè risoluzione spaziale**
- Si può misurare in pixel al centimetro, o in *dots per inch* (dpi) {*punti per pollice*}.
- Può anche essere espressa come il numero di pixel su tutta l’immagine (es. 16- Megapixel). Questa **non è una risoluzione spaziale**
La risoluzione indica il **grado di qualità massima raggiungibile** di un' immagine cioè **il più piccolo dettaglio che posso rappresentare.**

Per esempio:
- *Stampanti*: fino a 3000 dpi e oltre (per immagini molto grandi);
- *Schermi*: numero di elementi sullo schermo per unità di misura. Tipicamente 72 dpi.
![[Pasted image 20221103122832.png|550]]

![[Pasted image 20221103123020.png|450]]
![[Pasted image 20221103123038.png]] ![[Pasted image 20221103123028.png]]

>- Immagini nate con una certa risoluzione devono essere visualizzate con la stessa risoluzione per avere il massimo della resa.
>- Alcuni apparecchi diminuiscono i pixel (rispetto a quelli che dovrebbe rappresentare) che rappresentano, quindi usano un'apparecchiatura di resa poco efficiente o non sufficiente.